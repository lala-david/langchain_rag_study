{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNWQbXZmh08p577vwHMNg2f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lala-david/langchain_rag_study/blob/main/langchain_basics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kINyevvk3Lur",
        "outputId": "71c6db17-46cc-480c-c6ea-1838559a464e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m817.7/817.7 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.5/287.5 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.0/113.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.3/268.3 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.8/144.8 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q langchain langchain-openai tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = 'OPENAI_API_KEY'"
      ],
      "metadata": {
        "id": "75ajqwQf3XYh"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# model\n",
        "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
        "\n",
        "# chain 실행\n",
        "result = llm.invoke(\"우주의 나이는?\")"
      ],
      "metadata": {
        "id": "IB4rulLB375w"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(result.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IftFBxtE4gqD",
        "outputId": "f234ae87-8ecf-4a2f-bfc0-79ffdb40ecd5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "137억 년입니다. 초기 우주의 형성은 약 137억 년 전에 시작되었고 계속적으로 발전하고 변화해오고 있습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt1 = ChatPromptTemplate.from_template(\"translates {korean_word} to English.\")\n",
        "prompt2 = ChatPromptTemplate.from_template(\n",
        "    \"explain {english_word} using oxford dictionary to me in Korean.\"\n",
        ")\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
        "\n",
        "chain1 = prompt1 | llm | StrOutputParser()\n",
        "\n",
        "chain1.invoke({\"korean_word\":\"미래\"})"
      ],
      "metadata": {
        "id": "FW9ZbpT06Ttb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "# prompt + model + output parser\n",
        "prompt = ChatPromptTemplate.from_template(\"You are an expert in astronomy. Answer the question. : {input}\")\n",
        "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
        "output_parser = StrOutputParser()\n",
        "\n",
        "# LCEL chaining\n",
        "chain = prompt | llm | output_parser\n",
        "\n",
        "# chain 호출\n",
        "result = chain.invoke({\"input\": \"빅 크런치란?\"})\n",
        "\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBLz57Mw5F-F",
        "outputId": "0490f274-8f49-4211-db0f-f1be7aa61705"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "빅 크런치는 우주의 최종 운명 중 하나로, 우주가 끝없이 팽창하는 것이 아닌, 어느 순간에 갑자기 역으로 축소되어 다시 한 점으로 모이는 현상을 가리킵니다. 이는 우주의 끝을 예측하는 학자들 사이에서 논의되는 이론 중 하나이며, 빅 뱅 이후 우주의 운명에 대한 가설 중 하나입니다. 현재까지는 이론적인 가설에 불과하며, 관측적인 증거는 발견되지 않았습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2) Multiple Chains**"
      ],
      "metadata": {
        "id": "7yRCM_vy6pIq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt1 = ChatPromptTemplate.from_template(\"translates {korean_word} to English.\")\n",
        "prompt2 = ChatPromptTemplate.from_template(\n",
        "    \"explain {english_word} using oxford dictionary to me in Korean.\"\n",
        ")\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
        "\n",
        "chain1 = prompt1 | llm | StrOutputParser()\n",
        "\n",
        "chain1.invoke({\"korean_word\":\"미래\"})\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "_5lJ8ArD67Dg",
        "outputId": "7de5db9e-de00-4d4a-8c1f-0ada7d5463c6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'future'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain2 = (\n",
        "    {\"english_word\": chain1}\n",
        "    | prompt2\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "chain2.invoke({\"korean_word\":\"미래\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "5t3YLwQl69i6",
        "outputId": "19f48179-19ea-4dc2-8f9d-1a67cc159c42"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'미래는 \\'미래에 대한 시간적 관념\\' 또는 \\'어떤 것이 일어날 가능성\\'을 의미합니다. 예를 들어, \"미래에는 기술이 더욱 발전할 것이다\"와 같이 사용할 수 있습니다.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3) Prompt**"
      ],
      "metadata": {
        "id": "GVcZtvbG7deB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "# 'name'과 'age'라는 두 개의 변수를 사용하는 프롬프트 템플릿을 정의\n",
        "template_text = \"안녕하세요, 제 이름은 {name}이고, 나이는 {age}살입니다.\"\n",
        "\n",
        "# PromptTemplate 인스턴스를 생성\n",
        "prompt_template = PromptTemplate.from_template(template_text)\n",
        "\n",
        "# 템플릿에 값을 채워서 프롬프트를 완성\n",
        "filled_prompt = prompt_template.format(name=\"강성준\", age=23)\n",
        "\n",
        "filled_prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "MXLKgdj-7J0c",
        "outputId": "5332b48e-e571-4152-ea44-57eca39e1750"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'안녕하세요, 제 이름은 강성준이고, 나이는 23살입니다.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 문자열 템플릿 결합 (PromptTemplate + PromptTemplate + 문자열)\n",
        "combined_prompt = (\n",
        "              prompt_template\n",
        "              + PromptTemplate.from_template(\"\\n\\n아버지를 아버지라 부를 수 없습니다.\")\n",
        "              + \"\\n\\n{language}로 번역해주세요.\"\n",
        ")\n",
        "\n",
        "combined_prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXioBEvE712l",
        "outputId": "f20a8c41-1136-4dd4-e691-fa03fbbb7f85"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PromptTemplate(input_variables=['age', 'language', 'name'], template='안녕하세요, 제 이름은 {name}이고, 나이는 {age}살입니다.\\n\\n아버지를 아버지라 부를 수 없습니다.\\n\\n{language}로 번역해주세요.')"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "combined_prompt.format(name=\"강성준\", age=23, language=\"영어\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "MoLolvgI8Bgs",
        "outputId": "cefaeb6a-7d30-4a50-ebea-bf78add31363"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'안녕하세요, 제 이름은 강성준이고, 나이는 23살입니다.\\n\\n아버지를 아버지라 부를 수 없습니다.\\n\\n영어로 번역해주세요.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
        "chain = combined_prompt | llm | StrOutputParser()\n",
        "chain.invoke({\"age\":23, \"language\":\"영어\", \"name\":\"강성준\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "tpfM4Srj8IFs",
        "outputId": "82f5df9d-6536-426f-ec43-763aa50d64d9"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hello, my name is Kang Sungjun and I am 23 years old.\\n\\nI cannot call my father \"father.\"'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2-튜플 형태의 메시지 목록으로 프롬프트 생성 (type, content)\n",
        "\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "chat_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"이 시스템은 천문학 질문에 답변할 수 있습니다.\"),\n",
        "    (\"user\", \"{user_input}\"),\n",
        "])\n",
        "\n",
        "messages = chat_prompt.format_messages(user_input=\"태양계에서 가장 큰 행성은 무엇인가요?\")\n",
        "messages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAJ5ZUY_8Wae",
        "outputId": "345ea069-a773-47e2-9a8e-7266fe362fdd"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[SystemMessage(content='이 시스템은 천문학 질문에 답변할 수 있습니다.'),\n",
              " HumanMessage(content='태양계에서 가장 큰 행성은 무엇인가요?')]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain = chat_prompt | llm | StrOutputParser()\n",
        "\n",
        "chain.invoke({\"user_input\": \"태양계에서 가장 큰 행성은 무엇인가요?\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "nFTWG0KH9KQ3",
        "outputId": "2c2d2de7-c3c0-4df2-991b-a0b9e9e45ab5"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'태양계에서 가장 큰 행성은 목성입니다. 목성은 지름이 약 139,822 km로 태양계에서 가장 큰 크기를 가지고 있습니다.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4) Model Parameter**"
      ],
      "metadata": {
        "id": "UhHZ56u3-drH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import OpenAI\n",
        "\n",
        "llm = OpenAI()\n",
        "\n",
        "llm.invoke(\"한국의 대표적인 관광지 3군데를 추천해주세요.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "3pSil2PM-kmo",
        "outputId": "d059f7c2-37ea-47f4-c495-7b47420bf4dd"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\n1. 경복궁 - 서울에 위치한 조선 왕조의 왕궁으로, 한국의 전통적인 건축물과 문화를 감상할 수 있는 곳이다. 매년 수많은 외국인 관광객들도 찾는 인기 있는 관광지이다.\\n\\n2. 제주도 - 한국의 남쪽 끝에 위치한 제주도는 아름다운 자연 경관과 다양한 관광 명소를 갖고 있다. 섬 전체가 유네스코 세계자연유산으로 지정되어 있으며, 해변, 산, 동굴, 폭포 등 다양한 자연 경관을 즐길 수 있다.\\n\\n3. 부산 해운대 - 부산의 대표적인 해변으로 유명한 해운대는 넓은 해수욕장과 호'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "chat = ChatOpenAI()\n",
        "\n",
        "chat_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"이 시스템은 여행 전문가입니다.\"),\n",
        "    (\"user\", \"{user_input}\"),\n",
        "])\n",
        "\n",
        "chain = chat_prompt | chat\n",
        "chain.invoke({\"user_input\": \"안녕하세요? 한국의 대표적인 관광지 3군데를 추천해주세요.\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_ixip65-qVQ",
        "outputId": "51685622-d294-4c74-8975-4cea0d64983d"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='안녕하세요! 한국의 대표적인 관광지 3군데를 추천해드리겠습니다.\\n\\n1. 경복궁 (Gyeongbokgung) - 서울의 대표적인 궁궐로, 조선 시대에 건립된 역사적인 건물들이 모여 있습니다. 경복궁은 광화문 광장과 가까이에 위치해 있어 쉽게 방문할 수 있습니다.\\n\\n2. 부산 해운대해수욕장 (Haeundae Beach) - 부산의 대표적인 해변으로 깨끗한 백사장과 아름다운 바다 풍경을 자랑합니다. 여름에는 많은 관광객들이 모여 휴양을 즐기는 인기 있는 관광지입니다.\\n\\n3. 경주 (Gyeongju) - 고구려의 수도로 불리는 경주는 다양한 역사적인 유적지와 문화유산이 많이 보존되어 있습니다. 세계문화유산으로 등재된 석굴암이나 불국사 등을 방문하면 한국의 역사와 문화를 느낄 수 있습니다.\\n\\n이렇게 한국의 대표적인 관광지들을 방문해보시면 한국의 아름다운 자연과 역사를 경험할 수 있습니다. 어떤 지역이든 자세한 정보가 필요하시면 언제든지 물어보세요!', response_metadata={'token_usage': {'completion_tokens': 426, 'prompt_tokens': 59, 'total_tokens': 485}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_c2295e73ad', 'finish_reason': 'stop', 'logprobs': None}, id='run-766bdead-8a16-4f43-a2ce-3a80e005c218-0')"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **5) 모델 파라미터 설정**"
      ],
      "metadata": {
        "id": "1xduyVpb_Fk4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# 모델 파라미터 설정\n",
        "params = {\n",
        "    \"temperature\": 0.9,         # 생성된 텍스트의 다양성 조정\n",
        "    \"max_tokens\": 100,          # 생성할 최대 토큰 수\n",
        "}\n",
        "\n",
        "kwargs = {\n",
        "    \"frequency_penalty\": 0.5,   # 이미 등장한 단어의 재등장 확률\n",
        "    \"presence_penalty\": 0.5,    # 새로운 단어의 도입을 장려\n",
        "    \"stop\": [\"\\n\"]              # 정지 시퀀스 설정\n",
        "\n",
        "}ㅉ\n",
        "\n",
        "# 모델 인스턴스를 생성할 때 설정\n",
        "model = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", **params, model_kwargs = kwargs)\n",
        "\n",
        "\n",
        "# 모델 호출\n",
        "question = \"태양계에서 가장 큰 행성은 무엇인가요?\"\n",
        "response = model.invoke(input=question)\n",
        "\n",
        "# 전체 응답 출력\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7txrQRe9_Jt4",
        "outputId": "ef460610-7a70-4916-c9be-0eab9527201f"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content='가장 큰 행성은 목성(Jupiter)입니다. 목성은 태양계에서 지름, 질량, 부피 등이 가장 크고 어떤 다른 행성보다도 훨씬 큽니다. 이 행성은 가스로 이루어져 있으며 대기 중에는 수소와 헬륨이' response_metadata={'token_usage': {'completion_tokens': 100, 'prompt_tokens': 29, 'total_tokens': 129}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': 'fp_c2295e73ad', 'finish_reason': 'length', 'logprobs': None} id='run-672c571c-49f1-4a69-be86-6c1644abb6a6-0'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"이 시스템은 천문학 질문에 답변할 수 있습니다.\"),\n",
        "    (\"user\", \"{user_input}\"),\n",
        "])\n",
        "\n",
        "model = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", max_tokens=100)\n",
        "\n",
        "messages = prompt.format_messages(user_input=\"관측된 블랙홀 중 가장 큰 블랙홀은?\")\n",
        "\n",
        "before_answer = model.invoke(messages)\n",
        "\n",
        "# # binding 이전 출력\n",
        "print(before_answer)\n",
        "\n",
        "# 모델 호출 시 추가적인 인수를 전달하기 위해 bind 메서드 사용 (응답의 최대 길이를 10 토큰으로 제한)\n",
        "chain = prompt | model.bind(max_tokens=10)\n",
        "\n",
        "after_answer = chain.invoke({\"user_input\": \"관측된 블랙홀 중 가장 큰 블랙홀은?\"})\n",
        "\n",
        "# binding 이후 출력\n",
        "print(after_answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6QfAO7p_uen",
        "outputId": "f47e0db6-db91-4723-c22a-00849140aa4c"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content='2020년 9월 현재, 관측된 가장 큰 블랙홀은 M87 은하 중심에 위치한 블랙홀입니다. 이 블랙홀의 질량은 태양 질량의 약 65억 배에 달하며, 직경은 약 40억 km에 달합니다' response_metadata={'token_usage': {'completion_tokens': 100, 'prompt_tokens': 63, 'total_tokens': 163}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': 'fp_c2295e73ad', 'finish_reason': 'length', 'logprobs': None} id='run-e1ecd3b2-ebb0-4afa-ad26-4b2417f8976c-0'\n",
            "content='현재까지 관측된' response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 63, 'total_tokens': 73}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': 'fp_c2295e73ad', 'finish_reason': 'length', 'logprobs': None} id='run-39fb663e-8c09-4890-b9bf-94fe6eaf8843-0'\n"
          ]
        }
      ]
    }
  ]
}